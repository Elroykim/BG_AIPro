---
title: "2026 AI 기본법 시행: 개발자와 스타트업이 알아야 할 모든 것"
date: 2026-01-29
description: "2026년 1월 시행된 AI 기본법의 핵심 내용을 개발자와 스타트업 관점에서 정리합니다. 고영향 AI 분류, 투명성 의무, 과태료까지 실무 가이드."
categories: [AI]
tags: [AI 기본법, 인공지능 규제, AI 윤리, 스타트업]
keywords: [AI 기본법 2026, 인공지능 기본법 시행, 고영향 AI, 생성형 AI 투명성 의무, AI 기본법 과태료]
draft: true
cover:
  image: ""
  alt: ""
  hidden: false
slug: korea-ai-basic-law-2026-developer-guide
---

2026년 1월 22일부터 AI 기본법이 시행됐다. 정식 명칭은 「인공지능 발전과 신뢰 기반 조성 등에 관한 기본법」인데, EU AI Act보다 실제 적용이 빨라서 한국이 사실상 세계 최초로 포괄적 AI 규제를 시행한 셈이다.

뉴스 보고 "우리 서비스도 해당되나?" 싶어서 법령을 직접 읽어봤는데, 변호사 문서라 쉽지 않더라. 개발자와 스타트업 관점에서 핵심 내용을 정리했다.

---

## AI 기본법이란 무엇인가

### 제정 배경

2024년 12월 26일, 국회 본회의에서 재석 264명 중 찬성 260명이라는 압도적 지지로 통과된 법입니다. 핵심 목적은 두 가지입니다.

1. **AI 산업 진흥**: R&D 지원, 데이터 인프라 구축, 스타트업 육성 등 정부 지원의 법적 근거를 마련합니다.
2. **AI 신뢰 확보**: 고영향 AI와 생성형 AI에 대한 투명성, 안전성 의무를 법으로 규정합니다.

즉, 단순히 "규제합니다"가 아니라 **"키우면서 관리합니다"**라는 접근입니다. 법 자체가 '진흥 중심'을 표방하고 있어서, EU AI Act처럼 금지 목록을 두거나 천문학적 과징금을 매기는 방식과는 결이 다릅니다.

### 왜 개발자가 알아야 하는가

"나는 그냥 코드 짜는 사람인데?" 라고 생각할 수 있다. 나도 처음엔 그랬는데, 읽어보니 적용 대상이 생각보다 넓어서 좀 놀랐다.

- **AI 개발 사업자**: LLM이나 AI 모델을 직접 설계하고 제작하는 회사
- **AI 이용 사업자**: OpenAI API, Claude API 등 외부 모델을 가져다 서비스에 녹여 제공하는 회사

후자가 핵심입니다. ChatGPT API를 붙여서 고객 상담 챗봇을 만들어 서비스하는 스타트업도 법적 의무의 대상이 됩니다. 즉, 모델을 직접 학습시키지 않더라도 AI 기반 서비스를 외부에 제공하면 이 법의 규제를 받습니다.

> 단, 회사 내부에서만 사용하는 AI 도구(예: 사내 코드 리뷰 봇)는 이 법의 적용 범위 밖입니다.

---

## 법의 핵심 키워드 3가지

AI 기본법을 이해하려면 반드시 알아야 할 용어가 세 가지 있습니다.

### 1. 인공지능사업자

AI를 개발하거나 이를 활용해 제품/서비스를 제공하는 모든 사업자를 뜻합니다. 개발자뿐 아니라 배포자도 포함됩니다. 직접 LLM을 학습시키는 네이버, 카카오 같은 기업은 물론이고, 외부 API를 갖다 쓰는 소규모 SaaS 스타트업도 여기에 해당합니다.

### 2. 고영향 인공지능 (High-Impact AI)

사람의 생명, 신체의 안전, 기본권에 **중대한 영향**을 미치거나 위험을 초래할 우려가 있는 AI 시스템입니다. 법에서 정한 특정 영역에서 활용되는 경우에 해당하며, 가장 엄격한 의무가 적용됩니다.

### 3. 생성형 인공지능 (Generative AI)

텍스트, 이미지, 영상, 음성 등을 새로 만들어내는 AI 시스템입니다. LLM 기반 챗봇, 이미지 생성 모델, 음성 합성 도구 등이 모두 포함됩니다. 투명성 의무가 핵심입니다.

---

## 고영향 AI: 가장 중요한 분류 기준

### 고영향 AI 10대 영역

시행령에서 규정하는 고영향 AI의 적용 영역은 다음 10개입니다.

| 번호 | 영역 | 예시 |
|:---:|------|------|
| 1 | **에너지** | 전력 수급 예측, 스마트 그리드 운영 AI |
| 2 | **먹는 물** | 수질 관리, 정수 처리 공정 AI |
| 3 | **보건의료** | 질병 진단, 환자 분류 AI |
| 4 | **의료기기** | AI 기반 영상 진단 소프트웨어 |
| 5 | **원자력** | 원전 안전 관리, 핵물질 감시 AI |
| 6 | **범죄 수사** | 얼굴 인식, 범죄 예측 AI |
| 7 | **채용** | 이력서 스크리닝, AI 면접 평가 |
| 8 | **대출 심사** | 신용 평가, 자동 대출 승인 AI |
| 9 | **공공 서비스** | 복지 수급 결정, 행정 자동화 AI |
| 10 | **교육** | 학생 평가, 학습 경로 추천 AI |

### 고영향 AI 판단 3단계

단순히 위 10개 영역에 해당한다고 무조건 고영향 AI가 되는 것은 아닙니다. 시행령에서 정한 판단 기준은 다음과 같습니다.

1. **영역 해당 여부**: 위 10개 영역 중 하나에 속하는가?
2. **기본권 영향 여부**: 사람의 생명, 신체 안전, 기본권에 중대한 영향을 미치는가?
3. **세부 판단 기준**: 사용 빈도, 위험의 중대성, 영향을 받는 대상의 규모 등을 종합적으로 고려

즉, 교육 영역에서 AI를 쓰더라도 "단순 학습 콘텐츠 추천" 수준이라면 고영향으로 분류되지 않을 수 있지만, "AI가 학생의 진급 여부를 결정"하는 수준이라면 고영향 AI에 해당할 가능성이 높습니다.

### 고영향 AI 확인 신청 절차

자신의 서비스가 고영향 AI에 해당하는지 확실하지 않다면, **과학기술정보통신부(이하 과기정통부) 장관에게 확인을 요청**할 수 있습니다.

- 처리 기간: 기본 **30일**, 1회에 한해 30일 연장 가능 (최대 60일)
- 확인 요청은 의무가 아니라 선택이지만, 모호한 경우라면 적극 활용하는 것이 좋습니다

### "사람 중심 통제" 예외

AI가 자동으로 최종 결정을 내리는 것이 아니라, **사람이 최종 의사결정에 개입**하는 구조라면 고영향 AI 대상에서 제외될 수 있습니다. 이것은 기업 활동이 과도하게 위축되는 것을 막기 위한 장치입니다.

**개발자 관점에서의 시사점**: AI가 결과를 "제안"하고 사람이 "승인"하는 워크플로우를 설계하면, 고영향 AI 의무를 회피할 수 있는 구조가 됩니다. 예를 들어, 채용 AI가 합격자를 자동으로 결정하면 고영향이지만, 후보자 순위를 제안하고 인사담당자가 최종 결정하는 구조라면 예외 가능성이 있습니다.

---

## 투명성 의무: 개발자가 가장 먼저 대응해야 할 것

투명성 의무는 모든 AI 사업자에게 적용되는 핵심 의무입니다. 특히 생성형 AI를 서비스에 활용하는 개발자라면 바로 신경 써야 합니다.

### 사전 고지 의무

고영향 AI 또는 생성형 AI를 이용한 제품/서비스를 제공할 때, **이용자에게 해당 서비스가 AI 기반으로 운용된다는 사실을 사전에 알려야** 합니다.

실무적으로 이행하는 방법은 다음과 같습니다.

- 서비스 화면에 "이 응답은 AI가 생성했습니다" 문구 표시
- 이용약관에 AI 활용 사실 명시
- 앱이나 웹 서비스의 온보딩 과정에서 AI 사용 안내

### 생성형 AI 결과물 표시 의무 (워터마크)

생성형 AI가 만든 텍스트, 이미지, 영상, 음성 등에 대해 **AI로 생성된 결과물임을 이용자가 인식할 수 있도록** 표시해야 합니다.

구체적인 표시 방법은 다음과 같습니다.

| 결과물 유형 | 표시 방법 |
|------------|----------|
| **텍스트** | "AI가 생성한 콘텐츠입니다" 등의 문구 표시 |
| **이미지** | 시각적 워터마크 또는 메타데이터 삽입 |
| **영상** | 영상 내 "AI 생성" 표시 (딥페이크의 경우 처음부터 끝까지 가시적 워터마크 필수) |
| **음성** | AI 합성 음성임을 명시하는 안내 |

특히 **실제 인물의 얼굴이나 음성을 합성한 딥페이크 콘텐츠**에는 가장 엄격한 기준이 적용됩니다. 영상 전체에 걸쳐 사람 또는 기계가 판독할 수 있는 형식으로 AI 생성물임을 표시해야 합니다.

### 투명성 의무 면제 사항

모든 상황에서 워터마크를 달아야 하는 것은 아닙니다. 다음 경우에는 면제됩니다.

- **내부 업무 용도**: 회사 내부에서만 사용하는 AI 도구
- **명백한 경우**: 서비스명이나 이용자 화면에서 AI 기반 서비스임이 명확한 경우 (예: "AI 번역기"라는 서비스명 자체)
- **경미한 AI 처리**: 단순 색감 보정, 노이즈 제거 등 경미한 수준의 AI 처리

---

## 고영향 AI 사업자의 추가 의무

고영향 AI를 서비스에 활용하는 사업자에게는 일반 투명성 의무 외에 추가 의무가 부과됩니다.

### 안전성 및 신뢰성 조치 (6가지)

고영향 AI 사업자가 반드시 마련해야 하는 조치는 다음과 같습니다.

1. **위험관리방안**: AI 시스템의 잠재 위험을 식별하고 관리하는 계획
2. **설명 방안**: AI의 최종 결과 도출에 활용된 주요 기준과 원칙을 이용자에게 설명하는 방법
3. **학습 데이터 개요**: 학습에 사용된 데이터의 종류, 출처, 규모 등의 요약
4. **이용자 보호 방안**: 이용자의 권리 침해 시 구제 절차
5. **사람에 의한 관리/감독**: 인간 감독자(Human-in-the-loop) 체계
6. **문서 기록**: 위 조치들의 이행 내용을 문서로 기록하고 **5년간 보관**

### 홈페이지 공개 의무

위험관리방안의 주요 내용, AI 결과 도출 기준, 학습 데이터 개요, 이용자 보호 방안, 관리/감독 담당자의 성명과 연락처를 **홈페이지 등에 게시**해야 합니다.

### AI 영향 평가

고영향 AI를 제공하기 전에 기본권 영향 평가(FRIA, Fundamental Rights Impact Assessment)를 수행하도록 권고됩니다. 현재는 법적으로 "노력 의무"로 규정되어 있어 강제는 아니지만, 향후 의무화될 가능성이 있으므로 선제적으로 준비하는 것이 좋다. AI 윤리와 편향 문제의 기술적 대응은 [AI 윤리와 편향 가이드]({{< relref "posts/2026-01-28-ai-ethics-bias-guide.md" >}})에서 다루고 있다.

---

## 안전성 확보 의무와 고성능 AI 기준

### 누적 연산량 기준: 10^26 FLOPs

안전성 확보 의무가 적용되는 고성능 AI 시스템의 기준이 흥미롭습니다. 시행령에서는 **학습에 사용된 누적 연산량이 10의 26승 부동소수점 연산(FLOPs) 이상**인 시스템을 대상으로 합니다.

이것은 사실상 대형 파운데이션 모델 수준의 AI를 의미합니다. GPT-4, Claude, Gemini 같은 모델을 학습시키는 기업에 해당하는 기준이며, 대부분의 한국 스타트업에게는 직접적으로 해당되지 않을 것입니다.

다만, 이러한 고성능 AI 모델의 API를 사용해 서비스를 구축하는 경우에는 해당 모델의 안전성에 대한 책임이 API 제공자(OpenAI, Anthropic 등)에게 있지만, 서비스 레벨의 안전성은 여전히 서비스 사업자의 책임입니다.

---

## 과태료와 제재: 현실적으로 어느 정도인가

### 과태료 기준

| 위반 유형 | 과태료 금액 |
|----------|-----------|
| 고영향/생성형 AI 사전 고지 미이행 | **500만 원** (반복 시 최대 1,500만 원) |
| 해외 사업자 국내 대리인 미지정 | **2,000만 원** |
| 시정명령 미이행 | **최대 3,000만 원** |

### EU AI Act와 비교하면

| 구분 | 한국 AI 기본법 | EU AI Act |
|------|---------------|-----------|
| 최대 제재 | 3,000만 원 (~약 2만 유로) | 글로벌 매출의 최대 7% |
| 금지 AI 목록 | 없음 | 있음 (소셜 스코어링 등) |
| 접근 방식 | 진흥 중심, 유연한 규제 | 위험 기반, 엄격한 규제 |

한국의 과태료 수준은 EU와 비교하면 상당히 낮습니다. 하지만 가볍게 봐서는 안 됩니다.

- **시정명령**을 받고 이행하지 않으면 과태료뿐 아니라 **영업 정지** 등 행정 처분으로 이어질 수 있습니다
- 과태료는 위반 횟수에 따라 가중 부과됩니다
- 법이 성숙됨에 따라 제재 수준이 강화될 가능성이 높습니다

### 중소기업/벤처 감경

중소기업, 벤처기업, 소상공인의 경우 위법 상태 시정 노력 등을 고려해 **과태료를 50%까지 감경**받을 수 있습니다. 스타트업에게는 다소 위안이 되는 부분입니다.

### 계도 기간: 2027년까지는 유예

가장 현실적으로 중요한 포인트입니다. 과기정통부는 **법 시행 후 최소 1년 이상**의 계도 기간을 운영할 계획입니다.

- 법적 의무는 2026년 1월 22일부터 발생하지만, 실제 과태료 부과는 **빨라도 2027년 이후**
- 계도 기간 중에는 과기정통부가 운영하는 **통합안내지원센터**에서 기업 문의에 대한 상세 안내를 제공합니다
- 단, 인명 사고나 중대한 인권 침해 같은 예외적 상황에서는 계도 기간과 무관하게 사실조사가 진행될 수 있습니다

---

## 제도적 인프라: 알아두면 좋은 기관들

AI 기본법의 시행을 뒷받침하기 위해 여러 기관이 운영됩니다.

### 국가AI전략위원회 (구 국가인공지능위원회)

대통령 직속 위원회로, AI 관련 국가 정책의 전략적 조율과 성과 관리를 담당합니다. 3년마다 인공지능기본계획을 수립합니다. 부처 간 협업을 강화하는 국가인공지능책임관협의회도 운영합니다.

### AI안전연구소

AI 안전 정책, 기술, 표준화를 전담하는 연구소입니다. AI 시스템의 위험도 평가와 안전 기준 개발을 담당합니다.

### 인공지능정책센터

정책 개발과 국제 규범 정립을 담당합니다.

### AI 기본법 통합안내지원센터

서울 송파구 IT벤처타워에 위치한 지원센터로, 기업의 법 해석/적용 관련 문의에 대응합니다. 고영향 AI 해당 여부 확인 신청도 이곳을 통해 할 수 있습니다.

지원센터에는 한국지능정보사회진흥원(NIA), AI안전연구소, 한국정보통신기술협회(TTA), 정보통신정책연구원(KISDI) 등 전문 기관이 참여합니다.

---

## 개발자를 위한 실무 체크리스트

이론은 충분합니다. 이제 실제로 무엇을 해야 하는지 정리합니다.

### Step 1: 우리 서비스의 분류 확인

가장 먼저 해야 할 일은 자사 서비스가 어디에 해당하는지 파악하는 것입니다.

```
[ ] AI를 활용한 제품/서비스를 외부(고객)에 제공하는가?
    → No: 법 적용 대상 아님 (내부 사용만)
    → Yes: 아래 계속

[ ] 생성형 AI(텍스트/이미지/영상/음성 생성)를 활용하는가?
    → Yes: 투명성 의무 적용

[ ] 10대 고영향 영역에 해당하는가?
    → Yes: 고영향 AI 추가 의무 적용
    → 불확실: 과기정통부에 확인 요청
```

### Step 2: 투명성 의무 이행 (모든 AI 서비스)

```
[ ] 서비스 화면에 AI 사용 사실 고지 문구 추가
[ ] 이용약관에 AI 활용 사실 명시
[ ] 생성형 AI 결과물에 표시 방법 결정
    - 텍스트: 문구 표시
    - 이미지: 워터마크 또는 메타데이터
    - 영상/음성: 가시적 표시 또는 음성 안내
```

### Step 3: 고영향 AI 추가 조치 (해당하는 경우)

```
[ ] 위험관리방안 문서 작성
[ ] AI 결과 도출 기준 설명 방법 수립
[ ] 학습 데이터 개요 문서화
[ ] 이용자 보호 및 구제 절차 마련
[ ] Human-in-the-loop 감독 체계 구축
[ ] 위 조치 이행 내용 문서화 및 5년 보관 체계 구축
[ ] 홈페이지에 관련 정보 게시
```

### Step 4: 기술적 구현 사항

개발자가 코드 레벨에서 구현해야 할 것들입니다.

```python
# 예시: API 응답에 AI 생성 메타데이터 추가
response = {
    "content": ai_generated_text,
    "metadata": {
        "generated_by": "ai",
        "model": "gpt-4",
        "timestamp": "2026-01-29T10:00:00Z",
        "disclaimer": "이 콘텐츠는 인공지능에 의해 생성되었습니다."
    }
}
```

```python
# 예시: 이미지 생성 시 워터마크 삽입
from PIL import Image, ImageDraw, ImageFont

def add_ai_watermark(image_path, output_path):
    img = Image.open(image_path)
    draw = ImageDraw.Draw(img)
    draw.text(
        (10, 10),
        "AI 생성 이미지",
        fill=(255, 255, 255, 128)
    )
    img.save(output_path)
```

```python
# 예시: AI 의사결정 로깅 (5년 보관 대비)
import logging
import json
from datetime import datetime

def log_ai_decision(user_id, input_data, output, model_info):
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "user_id": user_id,
        "input_summary": input_data,
        "output": output,
        "model": model_info,
        "decision_criteria": "...",
        "human_reviewer": None  # 사람 검토 시 채워짐
    }
    # 5년 보관 가능한 스토리지에 저장
    logging.info(json.dumps(log_entry, ensure_ascii=False))
```

---

## 스타트업이 주의해야 할 실전 시나리오

### 시나리오 1: AI 기반 채용 SaaS

채용 AI는 고영향 AI 10대 영역에 포함됩니다.

- **해야 할 것**: 위험관리방안 수립, AI 판단 기준 설명 체계 구축, 학습 데이터 개요 공개, 이용자 보호 절차 마련, 홈페이지 공개
- **권장 설계**: AI가 "최종 합격/불합격"을 결정하는 것이 아니라, "후보자 순위를 추천"하고 인사담당자가 최종 결정하는 구조로 설계하면 "사람 중심 통제" 원칙으로 고영향 AI 의무 범위를 줄일 수 있습니다

### 시나리오 2: AI 이미지 생성 서비스

생성형 AI에 해당하므로 투명성 의무가 적용됩니다.

- **해야 할 것**: 생성된 이미지에 AI 생성 표시, 서비스 화면에 AI 사용 안내
- **특히 주의**: 실제 인물의 얼굴을 생성/합성하는 기능이 있다면 딥페이크 규정이 적용되어 가시적 워터마크가 필수입니다

### 시나리오 3: AI 기반 대출 심사 API 제공

대출 심사도 고영향 AI 영역입니다.

- **해야 할 것**: 고영향 AI 의무 전체 이행, 특히 "의미 있는 설명" 제공 체계가 핵심
- **실무 팁**: 이용자가 대출 거절 이유를 물었을 때, "AI가 판단했습니다"가 아니라 "소득 대비 부채 비율, 신용 이력 등을 종합적으로 고려한 결과입니다"처럼 구체적인 기준을 설명할 수 있어야 합니다

### 시나리오 4: 내부용 AI 코딩 어시스턴트

회사 내부에서만 사용하는 AI 도구는 법 적용 대상이 아닙니다.

- 외부 고객에게 제공하지 않는 사내 AI 도구는 규제 범위 밖
- 단, 이 도구의 결과물이 고객에게 전달되는 경우(예: AI가 작성한 코드가 고객용 제품에 포함)는 별도 검토가 필요합니다

---

## 해외 사업자 관련: 글로벌 서비스를 운영한다면

### 국내 대리인 지정 의무

국내에 주소나 영업소가 없는 해외 AI 사업자도, 다음 기준에 해당하면 **국내 대리인을 지정**해야 합니다.

- 전년도 말 기준 직전 3개월간 **국내 일평균 이용자 100만 명 이상**

이 기준은 주로 OpenAI, Google, Anthropic, Meta 같은 글로벌 AI 기업을 대상으로 하지만, 한국 시장에서 빠르게 성장하는 해외 AI 서비스도 해당될 수 있습니다.

- 미지정 시 과태료: **2,000만 원**

### 한국 스타트업이 해외에 서비스할 때

반대로, 한국 스타트업이 해외에 AI 서비스를 제공하는 경우에는 현지 법률(EU AI Act, 미국 주별 AI 규제 등)도 함께 검토해야 합니다. AI 기본법 준수만으로는 충분하지 않을 수 있습니다.

---

## 정부 지원 제도: 비용 부담을 줄이는 방법

AI 기본법은 규제만 있는 것이 아닙니다. 정부 지원 근거도 함께 마련되었습니다.

### 활용 가능한 지원

- **검증/인증 비용 지원**: 중소/벤처 대상으로 안전성/신뢰성 검증 및 인증 비용을 정부가 일부 지원합니다
- **AI 영향 평가 비용 지원**: 2026년 예산에 영향 평가 관련 지원 예산이 편성되었습니다
- **R&D 지원**: AI 산업 진흥을 위한 R&D 지원의 법적 근거가 마련되었습니다
- **학습 데이터 지원**: 공공데이터의 학습용 데이터 제공 근거가 마련되어, 정부 보유 데이터를 AI 학습에 활용할 수 있는 길이 열렸습니다
- **통합안내지원센터**: 법 적용에 관한 기업 문의에 무료로 상세 안내를 제공합니다

### 가이드라인 및 고시

한국지능정보사회진흥원(NIA)에서 고시와 가이드라인 초안을 공개했으며, 실무에 바로 쓸 수 있는 체크리스트와 예시가 포함되어 있습니다. 과기정통부 홈페이지와 통합안내지원센터를 통해 확인할 수 있습니다.

---

## 자주 묻는 질문 (FAQ)

### Q: 1인 개발자도 적용 대상인가요?

**A**: AI를 활용한 제품/서비스를 외부에 제공하고 수익을 얻는다면, 1인 개발자도 "인공지능사업자"에 해당합니다. 단, 중소기업/소상공인 감경 규정이 적용되어 과태료가 50%까지 줄어들 수 있습니다.

### Q: 오픈소스 AI 모델을 사용해도 적용되나요?

**A**: 네. 오픈소스 모델이든 상용 API든, 해당 모델을 활용해 외부에 서비스를 제공하면 AI 기본법의 적용을 받습니다. 중요한 것은 모델의 출처가 아니라 서비스 제공 여부입니다.

### Q: 지금 당장 뭔가 해야 하나요?

**A**: 법적 의무는 이미 발효되었지만, 과태료 계도 기간이 최소 1년 있으므로 즉시 벌금을 받을 위험은 낮습니다. 하지만 이 기간을 활용해 준비해야 합니다. 시정명령은 계도 기간과 무관하게 내려질 수 있습니다.

### Q: 개인정보보호법과 겹치는 부분은 어떻게 되나요?

**A**: AI 기본법은 개인정보보호법의 특별법이 아닙니다. 두 법은 별도로 적용되므로, AI가 개인정보를 처리하는 경우 양쪽 법률 모두 준수해야 합니다. 이용자 동의, 데이터 처리 목적 제한 등 개인정보보호법의 기존 의무는 그대로 유효합니다.

### Q: 계도 기간이 끝나면 바로 단속이 시작되나요?

**A**: 계도 기간 종료 후에도 정부는 단계적 접근을 취할 가능성이 높습니다. 하지만 인명 사고나 중대한 인권 침해가 발생하면 계도 기간과 관계없이 즉시 조치가 이루어질 수 있습니다.

---

## 타임라인 정리

| 시점 | 내용 |
|------|------|
| 2024년 12월 26일 | 국회 본회의 통과 (찬성 260, 반대 1, 기권 3) |
| 2025년 11월 12일 | 시행령 제정안 입법예고 |
| **2026년 1월 22일** | **AI 기본법 시행** |
| 2026년 중 | 고시/가이드라인 추가 공개, 통합안내지원센터 운영 |
| 2027년 1월 이후 | 계도 기간 종료, 과태료 부과 본격 시작 (예상) |

---

## 돌아보며: 준비하되, 두려워하지 말자

AI 기본법이 시행됐다는 뉴스를 보고 "이제 한국에서 AI 서비스 못 하는 거 아닌가?" 라고 걱정하는 분들이 있습니다. 결론부터 말하면, 그렇지 않습니다.

이 법은 EU AI Act처럼 특정 AI를 금지하거나, 글로벌 매출의 몇 퍼센트를 과징금으로 물리는 접근이 아닙니다. 과태료 상한도 3,000만 원으로 상대적으로 유연하고, 중소기업 감경 규정도 있으며, 1년 이상의 계도 기간도 제공됩니다.

다만, 이 기간을 "아직 안 해도 된다"가 아니라 **"준비할 시간이 있다"**로 받아들여야 합니다.

**지금 당장 할 수 있는 3가지**:

1. **분류 확인**: 자사 서비스가 고영향 AI, 생성형 AI, 일반 AI 중 어디에 해당하는지 파악합니다
2. **투명성 조치**: 서비스 화면에 AI 사용 사실을 고지하는 문구를 추가합니다 (가장 쉽고 즉시 가능)
3. **문서화 시작**: 고영향 AI에 해당한다면, 위험관리방안과 학습 데이터 개요 문서를 작성하기 시작합니다

AI 기본법은 한국 AI 생태계의 새로운 규칙입니다. 미리 준비하는 팀이 규제를 기회로 만들 수 있을 것입니다.

---

**참고 자료**:
- [국가법령정보센터 - AI 기본법 원문](https://www.law.go.kr/lsInfoP.do?lsiSeq=268543)
- [과기정통부 - 시행령 제정안](https://www.msit.go.kr/bbs/view.do?sCode=user&mId=307&mPid=208&pageIndex=2&bbsSeqNo=94&nttSeqNo=3186490)
- [법제처 - 입법예고](https://www.moleg.go.kr/lawinfo/makingInfo.mo?lawSeq=84360&lawCd=0&lawType=TYPE5&mid=a10104010000)
- [Cooley - South Korea's AI Basic Act Overview](https://www.cooley.com/news/insight/2026/2026-01-27-south-koreas-ai-basic-act-overview-and-key-takeaways)
- [IAPP - Analyzing South Korea's Framework Act](https://iapp.org/news/a/analyzing-south-korea-s-framework-act-on-the-development-of-ai)
- [CSET Georgetown - AI Law Translation](https://cset.georgetown.edu/publication/south-korea-ai-law-2025/)
